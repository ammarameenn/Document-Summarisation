## Inspiration
Text generation, which could be used, for instance, in text summarization, is one of the difficulties in natural language processing and comprehension. Actually, it entails comprehending the information a text conveys and condensing it into a brief summary that incorporates the essential, pertinent information. 
## Technique Used
It is obvious that a model works effectively on a text that is condensed and has just clear information and little noise. In this situation, we can use some extractive summarizers as the input of the summarization model to extract significant portions from a given text. I decided to use TF-IDF vectoriser to condense the text and extract the most crucial sentences. Then abstractive summarisation model is built using transformers which takes output of TF-IDF model as input and generate the abstract as required.
## Steps to built the summarizer

* Loading Dataset
* Preprocessing Datatset
* Extractive Summarization Model
  * TF-IDF summarizer
* Abstractive summarization Model
  * t5-base Transformer
### Loading Dataset
The NLTK corpus is a massive dump of all kinds of natural language data sets. Here I am loading Inaugral Dataset which includes Welcome speech of American presidents from 1789 to 2021.

I am in this notebook summarizing Joe Biden's Speech given by him.
### Text PreProcessing 
From tokenisation on sentence and word level to removing any HTML tags and all the basic preprocessing starts from here. All the contractions used in general english are also taken care of in this part.
### Extractive Summarisation Approach

* This method does not create new words or phrases, it just takes the already existing words and phrases and presents only that. You can imagine this as taking a page of text and marking the most important sentences using a highlighter.

* Extractive summarization methods work just like that. It takes the text, ranks all the sentences according to the understanding and relevance of the text, and presents you with the most important sentences. 

* There are many techniques to score sentences. Here I am using TF-IDF short for term frequencyâ€“inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.
After getting Sentence Scores, I average the score of all the sentences and took into account only 50 most important sentences from Joe Biden's speech.
### Abstractive summarization
* Abstractive summarization helps reduce the sentence size as it uses fusion to merge the sentences, thus helps achieve more non-redundancy in the summary as compared to the extractive summaries, where even the non-relevant part of sentence also gets included due to the fact that it extracts the sentences and arranges them.
* Up untill nnow we have extractive summary.
* Now I am using already pre trained model based on transformers called t5-base to train another model to create a short abstract of extractive summary.
